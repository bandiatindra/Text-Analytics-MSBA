{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:/Users/bandi/Desktop/Text Analytics/TA Session/chromedriver_win32/chromedriver')\n",
    "driver.get('https://forums.edmunds.com/discussion/2864/general/x/entry-level-luxury-performance-sedans/p702')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty data frame to store user_id, dates and comments from ~5K users.\n",
    "comments = pd.DataFrame(columns = ['Date','user_id','comments'])\n",
    "\n",
    "j = 702\n",
    "while (j>=1):\n",
    "    # Running while loop only till we get 5K comments \n",
    "    if (len(comments)<5000):\n",
    "        url = 'https://forums.edmunds.com/discussion/2864/general/x/entry-level-luxury-performance-sedans/p' + str(j)\n",
    "        driver.get(url)\n",
    "        ids = driver.find_elements_by_xpath(\"//*[contains(@id,'Comment_')]\")\n",
    "        comment_ids = []\n",
    "        for i in ids:\n",
    "            comment_ids.append(i.get_attribute('id'))\n",
    "\n",
    "        for x in comment_ids:\n",
    "            #Extract dates from for each user on a page\n",
    "            user_date = driver.find_elements_by_xpath('//*[@id=\"' + x +'\"]/div/div[2]/div[2]/span[1]/a/time')[0]\n",
    "            date = user_date.get_attribute('title')\n",
    "\n",
    "            #Extract user ids from each user on a page\n",
    "            user_title = driver.find_elements_by_xpath('//*[@id=\"' + x +'\"]/div/div[2]/div[1]/span[1]/a[1]')[0]\n",
    "            userid = user_title.get_attribute('title') \n",
    "\n",
    "            #Extract Message for each user on a page\n",
    "            user_message = driver.find_elements_by_xpath('//*[@id=\"' + x +'\"]/div/div[3]')[0]\n",
    "            comment = user_message.text\n",
    "           #Adding date, userid and comment for each user in a dataframe    \n",
    "            comments.loc[len(comments)] = [date,userid,comment]\n",
    "        j=j-1\n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "comments_copy = copy.deepcopy(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_space(s):\n",
    "    return s.replace(\"\\n\",\" \")\n",
    "comments_copy['comments'] = comments_copy['comments'].apply(remove_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_copy.to_csv('comments.csv', header=True, sep=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removepunc(item):\n",
    "    for p in punctuation:\n",
    "        item = item.replace(p,'')\n",
    "    return item\n",
    "\n",
    "def remove_numbers(s):\n",
    "    return re.sub(\"\\S*\\d\\S*\", \"\", s).strip()\n",
    "\n",
    "def lowerize(x):\n",
    "    return x.lower()\n",
    "\n",
    "comments_copy['comments_clean'] = comments_copy['comments'].apply(removepunc).apply(lowerize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'circlew saidthe lease rate is the factor that stops me cold from taking the leap since i dont track my cars it would do fine for my needs but i would assume an m2 would surpass the stinger on the track compared to the giuliayes the completely noncomparable m2 would beat the stinger on track as would a corvette or sportbike btw17 f150 crew 27 67 coronet rt 14 towncountry limited 09 lr2 hse 44car history and counting'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_copy['comments_clean'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.read_csv(\"models.csv\", header = None, names = ['brand','model'], encoding='windows-1252')\n",
    "\n",
    "models['brand'] = models['brand'].apply(removepunc)\n",
    "\n",
    "def model_to_brand(s):\n",
    "    for i in models.index.values:\n",
    "        s = s.replace(models[\"model\"][i].lower(),models[\"brand\"][i].lower())\n",
    "    return s\n",
    "comments_copy['comments_model_replace'] = comments_copy['comments_clean'].apply(model_to_brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = copy.deepcopy(comments_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['comments_appear'] = temp['comments_model_replace'].apply(word_tokenize).apply(set).apply(list)\n",
    "\n",
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(s):\n",
    "    return [w for w in s if not w in stop_words] \n",
    "    \n",
    "temp['final_comments'] =  temp['comments_appear'].apply(remove_stopwords)\n",
    "#filtered_sentence = [w for w in temp['comments_appear'] if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = []\n",
    "for i in range(len(temp)):\n",
    "    count+=temp['final_comments'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "word_freq = nltk.FreqDist(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acura',\n",
       " 'audi',\n",
       " 'bmw',\n",
       " 'buick',\n",
       " 'cadillac',\n",
       " 'car',\n",
       " 'chevrolet',\n",
       " 'chrysler',\n",
       " 'dodge',\n",
       " 'ford',\n",
       " 'honda',\n",
       " 'hyndai kia',\n",
       " 'hyundai',\n",
       " 'infiniti',\n",
       " 'kia',\n",
       " 'lincoln',\n",
       " 'mazda',\n",
       " 'mercedes',\n",
       " 'mercedes benz',\n",
       " 'mercedesbenz',\n",
       " 'mercury',\n",
       " 'mitsubishi',\n",
       " 'nissan',\n",
       " 'pontiac',\n",
       " 'problem',\n",
       " 'saturn',\n",
       " 'seat',\n",
       " 'sedan',\n",
       " 'subaru',\n",
       " 'suzuki',\n",
       " 'toyata',\n",
       " 'toyota',\n",
       " 'volkswagen',\n",
       " 'volkwagen',\n",
       " 'volvo']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_unique = models['brand'].drop_duplicates().tolist()\n",
    "models_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = word_freq.most_common(500)\n",
    "top_brands = []\n",
    "for (key, items) in top_words:\n",
    "    if key in models_unique:\n",
    "        model_counts = (key,items)\n",
    "        top_brands.append(model_counts)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task A: Identify top 10 brands by frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('car', 2289),\n",
       " ('bmw', 1595),\n",
       " ('audi', 1259),\n",
       " ('acura', 1158),\n",
       " ('hyundai', 769),\n",
       " ('volkswagen', 730),\n",
       " ('honda', 675),\n",
       " ('infiniti', 427),\n",
       " ('ford', 403),\n",
       " ('kia', 390),\n",
       " ('chrysler', 374),\n",
       " ('seat', 297),\n",
       " ('sedan', 292),\n",
       " ('problem', 273),\n",
       " ('cadillac', 259),\n",
       " ('mercedesbenz', 255),\n",
       " ('subaru', 227),\n",
       " ('volvo', 182),\n",
       " ('toyota', 141),\n",
       " ('nissan', 138),\n",
       " ('chevrolet', 129)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_brands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate lift ratios for associations between brands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
